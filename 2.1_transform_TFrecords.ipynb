{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ipynb reads COCO-format annotations json file and generates TFrecords for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from os import environ\n",
    "from pycocotools.coco import COCO\n",
    "from utils_library.configs import default_config as cfg, local_storage_config as storage_cfg\n",
    "cfg.__dict__.update(storage_cfg.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64_feature(value):\n",
    "    if type(value) != list:\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def encode_example(idd, image_raw, size, kpts, joints, mask):\n",
    "    kpts = tf.constant(kpts)\n",
    "    joints = tf.constant(joints)\n",
    "    mask = tf.constant(mask)\n",
    "    kpts = tf.io.serialize_tensor(kpts).numpy()\n",
    "    joints = tf.io.serialize_tensor(joints).numpy()\n",
    "    mask = tf.io.serialize_tensor(mask).numpy()\n",
    "\n",
    "    image_raw = image_raw.numpy()\n",
    "\n",
    "    feature = {\n",
    "        'id': int64_feature(idd),\n",
    "        'image_raw': bytes_feature(image_raw),\n",
    "        'size': int64_feature(size),\n",
    "        'kpts': bytes_feature(kpts),\n",
    "        # 'person_kpts_bbox': bytes_feature(kpts_bb),\n",
    "        'joints': bytes_feature(joints),\n",
    "        'mask': bytes_feature(mask),\n",
    "        # 'mask_bb': bytes_feature(mask_bb),\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "\n",
    "def middle_kpt(kpt1, kpt2):\n",
    "    \"\"\"Makes a middle keypoint from 2, if one of them is 0, also returns 0\"\"\"\n",
    "    if kpt1[2] == 0 or kpt2[2] == 0:\n",
    "        return 0, 0, 0\n",
    "    else:\n",
    "        return [\n",
    "            (kpt1[0] + kpt2[0]) / 2,\n",
    "            (kpt1[1] + kpt2[1]) / 2,\n",
    "            min(kpt1[2], kpt2[2])\n",
    "        ]\n",
    "\n",
    "\n",
    "def reshape_kpts(keypoints: list, config) -> np.ndarray:\n",
    "    \"\"\"reshapes keypoints list into numpy array\n",
    "    :param keypoints list of coco keypoints of  ...kpt x,kpt y,kpt visibility...\n",
    "    :param config the effective config\n",
    "    :returns np.ndarray of shape (DS_NUM_KEYPOINTS,3)\"\"\"\n",
    "    keypts_np = np.array(keypoints, dtype=np.float32)\n",
    "    keypts_np = keypts_np.reshape((config.DS_NUM_KEYPOINTS, 3))\n",
    "    return keypts_np\n",
    "\n",
    "\n",
    "def map_new_kpts(keypoints: np.ndarray, config) -> list:\n",
    "    \"\"\"\n",
    "    Map from dataset keypoints to own definition of keypoints, defined in KEYPOINTS_DEF.\n",
    "     for example dataset has no neck keypoint,this map it by averaging left and right shoulders\n",
    "     otherwise, it rearranges kpts in a more sensible order\n",
    "     \"\"\"\n",
    "    new_keypts = []\n",
    "    for kpt_name, kpt_def in config.KEYPOINTS_DEF.items():\n",
    "        ds_idxs = kpt_def[\"ds_idxs\"]\n",
    "        assert type(ds_idxs) is int or (type(ds_idxs) is tuple and len(ds_idxs) == 2)\n",
    "\n",
    "        if type(ds_idxs) is tuple:\n",
    "            first_kpt = keypoints[ds_idxs[0]]\n",
    "            second_kpt = keypoints[ds_idxs[1]]\n",
    "            new_kpt = np.array(middle_kpt(first_kpt, second_kpt), dtype=np.float32)\n",
    "        else:\n",
    "            new_kpt = keypoints[ds_idxs]\n",
    "        new_keypts.append(new_kpt)\n",
    "    return new_keypts\n",
    "\n",
    "\n",
    "def transform_keypts(keypoints, size: np.ndarray):\n",
    "    \"\"\"take the list form, numpyifies and forms to (number of persons,DS_NUM_KEYPOINTS,3) tensor,\n",
    "    also switches coords to match the rest of the system ie Y,X instead of X,Y\"\"\"\n",
    "\n",
    "    # keypts_np=np.array(keypts, dtype=np.float32)\n",
    "    # keypts_np=keypts_np.reshape((-1,DS_NUM_KEYPOINTS,3)) #form the list into a correctly shaped tensor\n",
    "\n",
    "    # critical, the incoming coords are in X,Y order, but everything else is in Y,X order!\n",
    "    X = np.array(keypoints[..., 0], dtype=np.float32)\n",
    "    Y = np.array(keypoints[..., 1], dtype=np.float32)\n",
    "    keypoints[..., 0] = Y\n",
    "    keypoints[..., 1] = X\n",
    "\n",
    "    # normalizing now saves this computation later for every tensor\n",
    "    # the pixel idx get normalized to 0..1 range so pixel at (100,300) on a (400,600) sized image becomes (0.25,0.5)\n",
    "    keypoints[:, :, 0:2] = keypoints[:, :, 0:2] / size\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "def create_all_joints(all_keypts, config):\n",
    "    \"\"\"create a joints tensor from keypoints tensor, according to COCO joints\n",
    "    :param config: effective config dict, must include JOINTS_DEF\n",
    "    :param all_keypts - tensor of shape (number of persons,number of kpts(DS_NUM_KEYPOINTS),3)\n",
    "    :return tensor of shape (number of persons,number of joints(19),5)\"\"\"\n",
    "\n",
    "    def create_joints(keypts):\n",
    "        joints = []\n",
    "        for joint_name, joint_def in config.JOINTS_DEF.items():\n",
    "            kp1_name, kp2_name = joint_def[\"kpts\"]\n",
    "            kp1_idx = config.KEYPOINTS_DEF[kp1_name][\"idx\"]\n",
    "            kp2_idx = config.KEYPOINTS_DEF[kp2_name][\"idx\"]\n",
    "            kp1 = keypts[kp1_idx]\n",
    "            kp2 = keypts[kp2_idx]\n",
    "            if kp1[2] == 0 or kp2[2] == 0:\n",
    "                # if either of the keypoints is missing, the joint is zero\n",
    "                new_joint = (0, 0, 0, 0, 0)\n",
    "                joints.append(new_joint)\n",
    "                continue\n",
    "            # create new joint from both keypoint coords, with the visibility being the minimum of either keypoint\n",
    "            new_joint = (*kp1[0:2], *kp2[0:2], min(kp1[2], kp2[2]))\n",
    "            joints.append(new_joint)\n",
    "        return np.array(joints, dtype=np.float32)\n",
    "\n",
    "    all_joints = [create_joints(x) for x in all_keypts]  # for each person\n",
    "\n",
    "    # numpify result transpose joints\n",
    "    return np.array(all_joints, dtype=np.float32).transpose((1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileSharder:\n",
    "    def __init__(self, file_writer, base_filename_format: str, records_per_file: int, verbose: bool = True):\n",
    "        \"\"\"Provides a convenient interface to write TFrecord files with auto sharding\n",
    "        :param base_filename_format the full path to a single file, must include single {} for .format()\n",
    "        :param file_writer, is the class to use as a writer, must have .write()\"\"\"\n",
    "        assert base_filename_format.format(0) != base_filename_format\n",
    "\n",
    "        self._file_writer = file_writer\n",
    "        self._base_filename_format = base_filename_format\n",
    "        self._records_per_file = records_per_file\n",
    "        self._example_counter = 0\n",
    "        self._file_counter = 1\n",
    "        self._verbose = verbose\n",
    "        self._start_file()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def _start_file(self):\n",
    "        self._filename = self._base_filename_format.format(self._file_counter)\n",
    "        if self._verbose: print(\"\\nWriting file:\" + self._filename, flush=True)\n",
    "        self._writer = self._file_writer(self._filename)\n",
    "\n",
    "    def _finish_file(self):\n",
    "        self._writer.flush()\n",
    "        self._writer.close()\n",
    "\n",
    "    def _advance_file(self):\n",
    "        self._finish_file()\n",
    "        self._file_counter += 1\n",
    "        self._example_counter = 0\n",
    "        self._start_file()\n",
    "\n",
    "    def write(self, item):\n",
    "        \"\"\"write a single item, sharded files will be created as needed\"\"\"\n",
    "        self._writer.write(item)\n",
    "        if self._verbose and not self._example_counter % 100: print(\".\", end=\"\", flush=True)\n",
    "        self._example_counter += 1\n",
    "        if not self._example_counter % self._records_per_file:\n",
    "            self._advance_file()\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self._finish_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_to_TFrecords(keypoint_annotations_file, transformed_annotations_file, images_path, config):\n",
    "    \"\"\"This script transforms the COCO 2017 keypoint train,val files\n",
    "    into a format with all keypoints and joints for an image, in a more convenient format,\n",
    "    where the first axes is the body part or joint, the second is the object, and the third are the\n",
    "    components (x,y,a) for keypoint and (x1,y1,x2,y2,a) for joint.\n",
    "    The script saves it into matching pickle files.\n",
    "    Meant to run once.\n",
    "    normalizes size the pixel coords to be normalized by size to 0..1 range\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nReading \" + keypoint_annotations_file)\n",
    "\n",
    "    coco = COCO(keypoint_annotations_file)  # cocoapi中定义的COCO类的实例\n",
    "    imgIds = coco.getImgIds()  # 所有符合要求（存在人）的imgIds list\n",
    "    imgIds.sort()\n",
    "    print(\"Found %d images\" % len(imgIds))\n",
    "\n",
    "    files_path = transformed_annotations_file + \"-{:03}.tfrecords\"\n",
    "    with FileSharder(tf.io.TFRecordWriter, files_path, config.IMAGES_PER_TFRECORD) as writer:\n",
    "        for img_id in imgIds: # 对于每一章图片\n",
    "            \n",
    "            #if img_id != pre_set_id:\n",
    "                #continue\n",
    "            \n",
    "            #print(img_id)\n",
    "            \n",
    "            img_info = coco.loadImgs(img_id)[0] # 读取每张图片的信息\n",
    "            \n",
    "\n",
    "            size = [img_info['height'], img_info['width']]\n",
    "\n",
    "            annIds = coco.getAnnIds(imgIds=[img_id]) # 读取该图片对应的annotation Id\n",
    "            anns = coco.loadAnns(annIds) # 读取该图片对应的annotation\n",
    "            \n",
    "\n",
    "            persons_kpts = []\n",
    "            for annotation in anns:\n",
    "                if annotation['num_keypoints'] > 0:\n",
    "                    kpts = annotation['keypoints']\n",
    "\n",
    "                    # map to new kpts\n",
    "                    kpts = reshape_kpts(kpts, config)\n",
    "                    kpts = map_new_kpts(kpts, config)\n",
    "                    \n",
    "                    persons_kpts.append(kpts)\n",
    "\n",
    "            if not persons_kpts:\n",
    "                continue  # this means that the image has no people with keypoints annotations\n",
    "\n",
    "            persons_kpts = np.array(persons_kpts, dtype=np.float32)  # convert from list to array\n",
    "            \n",
    "\n",
    "            keypoints = transform_keypts(persons_kpts, np.array(size, dtype=np.int))\n",
    "            tr_joint = create_all_joints(keypoints, config)\n",
    "            tr_keypoints = keypoints.transpose((1, 0, 2))  # transpose keypoints for later stages\n",
    "            \n",
    "            total_mask = np.zeros(size, dtype=np.float32)\n",
    "            \n",
    "            for annotation in anns:\n",
    "                if annotation['num_keypoints'] == 0:  # only mask those without keypoints\n",
    "                    single_mask = coco.annToMask(annotation)\n",
    "                    total_mask = np.max([total_mask, single_mask], axis=0)\n",
    "\n",
    "            total_mask = cv2.resize(total_mask, (config.LABEL_WIDTH, config.LABEL_HEIGHT))\n",
    "            total_mask = (total_mask > 0.01).astype(np.int16)\n",
    "\n",
    "            kernel = np.ones((5, 5), np.uint8)\n",
    "            total_mask = cv2.dilate(total_mask, kernel)  # get more area after downsample\n",
    "            total_mask = total_mask.astype(np.bool)\n",
    "            total_mask = np.invert(total_mask)  # invert for loss multiplication later\n",
    "            total_mask = total_mask.astype(np.float32)\n",
    "            \n",
    "            try:\n",
    "                img_path = images_path + \"/\" + img_info['file_name']\n",
    "                image_raw = tf.io.read_file(img_path)\n",
    "            except:\n",
    "                print(\"Couldn't read file %s\" % img_path)\n",
    "                continue\n",
    "                \n",
    "            example = encode_example(img_id, image_raw, size, tr_keypoints, tr_joint, total_mask)\n",
    "            writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading /Users/alextrasza/Desktop/Capstone_project/Original_Models/Yet-Another-Openpose-Implementation/utils_library/configs/../../self_dataset/RGB_Dataset/RGB_train_annotations.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Found 263 images\n",
      "\n",
      "Writing file:/Users/alextrasza/Desktop/Capstone_project/Original_Models/Yet-Another-Openpose-Implementation/utils_library/configs/../../self_dataset/RGB_Dataset/TFrecords/training-001.tfrecords\n",
      ".\n",
      "Writing file:/Users/alextrasza/Desktop/Capstone_project/Original_Models/Yet-Another-Openpose-Implementation/utils_library/configs/../../self_dataset/RGB_Dataset/TFrecords/training-002.tfrecords\n",
      ".\n",
      "Writing file:/Users/alextrasza/Desktop/Capstone_project/Original_Models/Yet-Another-Openpose-Implementation/utils_library/configs/../../self_dataset/RGB_Dataset/TFrecords/training-003.tfrecords\n",
      ".\n",
      "Reading /Users/alextrasza/Desktop/Capstone_project/Original_Models/Yet-Another-Openpose-Implementation/utils_library/configs/../../self_dataset/RGB_Dataset/RGB_val_annotations.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Found 66 images\n",
      "\n",
      "Writing file:/Users/alextrasza/Desktop/Capstone_project/Original_Models/Yet-Another-Openpose-Implementation/utils_library/configs/../../self_dataset/RGB_Dataset/TFrecords/validation-001.tfrecords\n",
      "."
     ]
    }
   ],
   "source": [
    "coco_to_TFrecords(cfg.TRAIN_ANNS, cfg.TRAIN_TFRECORDS, cfg.TRAIN_IMAGES_PATH, cfg)\n",
    "coco_to_TFrecords(cfg.VALID_ANNS, cfg.VALID_TFRECORDS, cfg.VALID_IMAGES_PATH, cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
